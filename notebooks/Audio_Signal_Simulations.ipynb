{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9be07ef-accf-4cbd-8c26-2edc0a0221fa",
   "metadata": {},
   "source": [
    "## Simulation of Digital Signal Processing Algorithms\n",
    "\n",
    "\n",
    "\n",
    "The following note book is provided to simulate audio signals for the purpose of visulaising the perfomance of \n",
    "signal processing algorithms, and techniques for time difference of arrival method.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Author: Kananelo Chabeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27c30e-06c2-4c6e-a9d7-eaf55e5f5eb0",
   "metadata": {},
   "source": [
    "### ------------------------------Imports-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aed064ec-9a67-4d9a-80e7-29327e854de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import sounddevice as sd\n",
    "from scipy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave as wv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f8db8-4c65-4c3d-b1fc-b1dbc6bdfd27",
   "metadata": {},
   "source": [
    "### Implementation of functions that read and record the wave audio files*****************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb53380-4b6f-4cbc-96a5-b6540b7cff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that reads a wave file from the given file name and returns raw wave file data and sample rate\n",
    "def read_wav(filename,play=False):\n",
    "    rate,data=io.wavfile.read(filename)\n",
    "    if play:\n",
    "        sd.play(data,rate)\n",
    "    return data,rate\n",
    "def record_wav(filename,duration,sampling_rate,channels=1):\n",
    "    recording=sd.rec(int(duration*sampling_rate),samplerate=sampling_rate,channels=channels) #record sound\n",
    "    sd.wait() #wait for the recording to complete\n",
    "    io.wavfile.write(filename,sampling_rate,recording)\n",
    "    return recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8224c-95dc-4212-a046-a91d4d64f6b3",
   "metadata": {},
   "source": [
    "### Implementation of functions that plot signals in desired domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e40bbe-dcff-4b3c-a5b9-2bfa49fdf85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that computes time axis samples for time-domain plotting\n",
    "def time_axis(samples,step):\n",
    "    return np.linspace(0,(samples-1)*step,int(samples))\n",
    "#function that generates frequency axis samples for frequency domain plot\n",
    "\n",
    "def freq_axis(samples,time_step):\n",
    "    freq_step=1/(samples*time_step) #samples spacing in frequency domain\n",
    "    if samples % 2 == 0:\n",
    "       return  np.arange((-samples/2)*freq_step,((samples/2))*freq_step,freq_step)\n",
    "    return np.arange((-(samples+1)/2)*freq_step,((samples-1)/2)*freq_step,freq_step)\n",
    "#coming\n",
    "def time_plot(t,xv,start=0,end=1000,title=\"Time domain plot of the signal\",\n",
    "              ylab=\"magnitudes\",label=\"signal1\",figure=1):\n",
    "    if len(t)!=len(xv):\n",
    "        print(\"Given arrays must have same dimesions!\")\n",
    "        return\n",
    "    plt.figure(figure)\n",
    "    plt.plot(t,xv,label=label)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"time(s)\")\n",
    "    plt.show()\n",
    "#coming\n",
    "def spectral_plot(f,xv,time_step,title=\"Spectral plot of the signal\",\n",
    "                  ylab=\"magnitude\",plot=True):\n",
    "    if len(f) !=len(xv):\n",
    "        print(\"Given arrays must have same dimesions!\")\n",
    "        return None\n",
    "    XV=np.fft.fft(xv)\n",
    "    XV_Abs=time_step*np.fft.fftshift(np.abs(XV))\n",
    "    if plot:\n",
    "        plt.plot(f,XV_Abs)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Frequency(Hz)\")\n",
    "        plt.ylabel(ylab)\n",
    "        plt.show()\n",
    "    return XV\n",
    "#comming\n",
    "def spectrogral_plot(data,rate,title=\"Spectrogram of the Signal\"):\n",
    "    f,t,Sxx=signal.spectrogram(data,rate) #Compute the spectrum\n",
    "    plt.pcolormesh(t, f, Sxx) #plot the spectrum\n",
    "    #plt.specgram(data,rate)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"$Frequency(Hz)$\")\n",
    "    plt.xlabel(\"$Time(s)$\")\n",
    "    plt.colorbar(label=\"$intensity(dB)$\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756570be-9329-4af9-a8eb-c6c97b4baf67",
   "metadata": {},
   "source": [
    "### Implementation of Finite Impulse Respose Low Pass Filter for Audio Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6564ba4-2357-48dc-b211-a2a6b4ce9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following fucntion applies Finite Impulse Respose Filter on the signal passed and returns the filtered signal\n",
    "def finite_impulse_response_filter(target_signal,cut_off,sampling_rate,length=29,width=10,response=False):\n",
    "    \"\"\"\n",
    "        This function designs and applies a low pass Finite Impulse Respose filter\n",
    "        on the target_singnal for the given sampling rate, cut_off frequency and transition region width. \n",
    "        The function plots the filter respose if the parameter 'response' is set to true, and returns the filtered signal \n",
    "    \"\"\"\n",
    "    #-----------------Define the Nyquist Frequency-------------\n",
    "    Nyquist_rate=sampling_rate/2\n",
    "    #----------------Define Normalized cut-off frequency-------\n",
    "    normalized_cutoff=cut_off/Nyquist_rate\n",
    "    #---------------Obtain the filter coeficients--------------\n",
    "    filter_coeff=signal.firwin(length,normalized_cutoff,width=width)\n",
    "    if response:\n",
    "        [w,h]=signal.freqz(filter_coeff,worN=20_000)\n",
    "        w=sampling_rate*w/(2*np.pi)\n",
    "        h_db=20*np.log10(abs(h))\n",
    "        plt.plot(w,h_db)\n",
    "        plt.title(\"Frequency Response of the Finite Impulse Response Low Pass\")\n",
    "        plt.ylabel(\"Magnitude(dB)\")\n",
    "        plt.xlabel(\"Frequency(Hz)\")\n",
    "        plt.show()\n",
    "    filtered_signal=signal.lfilter(filter_coeff,1.0,target_signal)\n",
    "    return filtered_signal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86533b-b18a-434c-b4a6-ea214d9d1584",
   "metadata": {},
   "source": [
    "## Implement Functions that perform Generalized Cross Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fea42-9f83-4023-8161-259fd3e11ccc",
   "metadata": {},
   "source": [
    "### 1: Generalized Cross Correlation Phase Transform : GCC-PHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3375226d-5a4c-4849-8086-cd3315a85b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(reference_signal,signal,rate,interp=16):\n",
    "    \"\"\"\n",
    "        This function takes two signals, cross-correlate them and then returns the estimated time delay between those signals.\n",
    "        ---------\n",
    "        Parameters:\n",
    "            reference_signal(ndarray): signal taken as the reference signal\n",
    "            signal(ndarray)          : signal cross_correlated with the reference signal\n",
    "            rate(int)                : number of samples per seconds for the signals(signals are assumed to be \n",
    "            interp(int)              : Ineteger that control accuracy of GCC-PHAT Algorithm\n",
    "        Returns:\n",
    "            delay(double)            : Estimated time delay between signals\n",
    "            cross_Corr(ndarray)      : Array of cross correlatio function between signal\n",
    "    \"\"\"\n",
    "    length = signal.shape[0] + reference_signal.shape[0]\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    SIGNAL = np.fft.fft(signal, n=length)\n",
    "    REFERENCESIGNAL = np.fft.fft(reference_signal, n=length)\n",
    "    #Compute Cross-spectral Density of the signals\n",
    "    CSD = REFERENCESIGNAL * np.conj(SIGNAL)\n",
    "    #Actual GCC-PHAT Alorithm\n",
    "    cross_corr = np.fft.ifft(CSD / np.abs(CSD), n=(interp * length))\n",
    "\n",
    "    max_shift = int(interp * length/ 2)\n",
    "    cross_corr = np.concatenate((cross_corr[-max_shift:], cross_corr[:max_shift+1]))\n",
    "    \n",
    "    # find max cross correlation index\n",
    "    shift = np.argmax(np.abs(cross_corr)) - max_shift\n",
    "    #Find refusling time shift in seconds\n",
    "    delay = shift / float(interp * rate)\n",
    "    \n",
    "    return np.abs(delay), cross_corr #Return absolute value of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2eb80ed-fe6c-4ad4-8c63-ddec6e83080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function that creates a known delay of the given audio data.\n",
    "\n",
    "def delay_audio(audio_data,rate,delay,write=False,filename='output.wav'):\n",
    "    \"\"\"\n",
    "        This function takes audio data,sampling rate and delay is seconds.\n",
    "        It created a delayed versionof the audio, delyed by the given number of seconds.\n",
    "        ------------\n",
    "        Parameters:\n",
    "        audio_data(ndarray): raw audio data\n",
    "        rate(int)          : sampling rate of the audio\n",
    "        delay(double)      : Required delay is seconds\n",
    "        write(bool)        : if True, resulting audio will be saved to given filename\n",
    "        filename(str)      : filename of the output file, if write set to True\n",
    "\n",
    "        Returns:\n",
    "        ndarray of the  delayed data\n",
    "    \"\"\"\n",
    "    sample_delay=int(delay*rate)\n",
    "    ret=np.concatenate((np.zeros(sample_delay),audio_data)) \n",
    "    if write:\n",
    "        io.wavfile.write(filename,rate,ret.astype(np.int16))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b11c93b5-72a9-4d30-8547-f2141a3fc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import struct\n",
    "\n",
    "def read_stereo_wave(file_path):\n",
    "    \"\"\"\n",
    "    Read a stereo wave file and return a tuple of two channels.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the stereo wave file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists, one for each channel's audio data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the wave file for reading\n",
    "        with wv.open(file_path, 'rb') as wave_file:\n",
    "            # Get the number of channels in the wave file\n",
    "            num_channels = wave_file.getnchannels()\n",
    "            \n",
    "            # Ensure it's a stereo wave file\n",
    "            if num_channels != 2:\n",
    "                raise ValueError(\"Input file is not a stereo wave file.\")\n",
    "            \n",
    "            # Get the frame size in bytes\n",
    "            frame_size = wave_file.getsampwidth() * num_channels\n",
    "            \n",
    "            # Read audio data from both channels\n",
    "            channel1_data = []\n",
    "            channel2_data = []\n",
    "            while True:\n",
    "                frame = wave_file.readframes(1)\n",
    "                if not frame:\n",
    "                    break\n",
    "                # Unpack the stereo data into two channels\n",
    "                sample = struct.unpack(f\"<{num_channels}h\", frame)\n",
    "                channel1_data.append(sample[0])\n",
    "                channel2_data.append(sample[1])\n",
    "            \n",
    "            return (channel1_data, channel2_data)\n",
    "    \n",
    "    except wv.Error as e:\n",
    "        print(f\"Error reading wave file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# channels = read_stereo_wave(\"stereo_file.wav\")\n",
    "# channel1_data, channel2_data = channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a6f49d5-4ba6-45f2-91cb-5f4958092260",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unpack requires a buffer of 4 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data1,data2\u001b[38;5;241m=\u001b[39m\u001b[43mread_stereo_wave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 35\u001b[0m, in \u001b[0;36mread_stereo_wave\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Unpack the stereo data into two channels\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_channels\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m channel1_data\u001b[38;5;241m.\u001b[39mappend(sample[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     37\u001b[0m channel2_data\u001b[38;5;241m.\u001b[39mappend(sample[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 4 bytes"
     ]
    }
   ],
   "source": [
    "\n",
    "data1,data2=read_stereo_wave('file.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a46be-493f-4e56-b295-c68100777b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef725462-2993-4bac-9d57-d2ab04bc86b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
